{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586476ef",
   "metadata": {},
   "source": [
    "# AIMPED’s NeuroBot: Your Gateway to the World of Neurology\n",
    "\n",
    "<div style=\"text-align: justify;\">\n",
    "Take a dive into the world of neurology with AIMPED's NeuroBot as your guide. This advanced chatbot is here to change how you learn about the brain. Get quick and precise answers to your questions, making complex medical stuff easier to understand than ever before.\n",
    "\n",
    "\n",
    "## NeuroBot: Redefining Access to Neurological Information\n",
    "Understanding the complexities of neurology might seem overwhelming, whether you're a medical expert or just someone curious about how the brain works. But with AIMPED's NeuroBot, you have a friendly companion to help you navigate this fascinating field. It provides a simple and easy way to explore all things neurological, empowering you to learn with confidence.\n",
    "\n",
    "\n",
    "## Who Can Benefit from NeuroBot?\n",
    "AIMPED's NeuroBot caters to a diverse audience, including:\n",
    "- <b>Medical Professionals:</b> Neurologists, neurosurgeons, physicians, and medical students can rely on NeuroBot to access comprehensive information on neurological conditions, diagnostic procedures, treatment modalities, and more.\n",
    "- <b>Patients and Caregivers:</b> Empowering patients and their caregivers with valuable insights into neurological disorders, NeuroBot provides clear explanations, treatment options, and lifestyle recommendations to support their journey towards improved health outcomes.\n",
    "- <b>Researchers and Academicss:</b> From conducting literature reviews to exploring cutting-edge research in neurology, NeuroBot serves as a valuable tool for researchers, academics, and students alike, offering access to up-to-date information and educational resources.\n",
    "- <b>General Enthusiasts:</b> Whether you're fascinated by the inner workings of the brain or simply curious about neurological phenomena, NeuroBot welcomes users of all backgrounds to delve into the captivating world of neurology.\n",
    "\n",
    "\n",
    "## Real-World Scenarios: How NeuroBot Can Help You\n",
    "- <b>Diagnostic Assistance:</b> A physician encounters a complex case involving neurological symptoms. With NeuroBot's assistance, the physician can quickly access relevant information to aid in the diagnostic process, ensuring timely and accurate patient care.\n",
    "- <b>Patient Education:</b> A newly diagnosed patient seeks to understand their neurological condition and treatment options. NeuroBot provides the patient with accessible explanations and educational materials, empowering them to actively participate in their healthcare journey.\n",
    "- <b>Research Support:</b> A neuroscience researcher is conducting a study on a rare neurological disorder. NeuroBot assists the researcher by providing access to pertinent literature, case studies, and clinical trials, facilitating the advancement of knowledge in the field.\n",
    "- <b>Educational Tools:</b> A medical student preparing for exams turns to NeuroBot for supplemental learning resources. With its vast repository of information and interactive interface, NeuroBot enhances the student's understanding of complex neurological concepts.\n",
    "\n",
    "\n",
    "## Why Choose AIMPED's NeuroBot?\n",
    "- <b>Cutting-Edge Technology:</b> NeuroBot utilizes advanced technology to swiftly provide tailored information from reliable sources, ensuring precise and relevant responses.\n",
    "- <b>Reliability Guaranteed:</b> Trust NeuroBot to deliver accurate information thoroughly checked from trusted neurology sources.\n",
    "- <b>Personalized Assistance:</b> Receive tailored support that fits your questions and preferences, regardless of your background.\n",
    "- <b>User-Friendly Interface:</b> NeuroBot's intuitive design and conversational AI make it easy for users of all skill levels to engage with, ensuring accessibility for everyone.\n",
    "- <b>Expand Your Knowledge:</b> Dive into the world of neurology and enrich your understanding with NeuroBot's extensive educational insights, presented in a clear and engaging manner.\n",
    "- <b>Ethical Information Sourcing:</b> NeuroBot adheres to strict ethical standards in sourcing information, ensuring responsible content that upholds factual accuracy and integrity.\n",
    "\n",
    "\n",
    "## How to Use\n",
    "Accessing NeuroBot is simple and straightforward:\n",
    "- Navigate to the [Aimped’s NeuroBot](https://dev.aimped.ai/models/neurology-assistant-a-comprehensive-guide-for-neurological-insights-491)  webpage.\n",
    "- Input your neurological query or topic of interest into the chat window.\n",
    "- AIMPED's NeuroBot will promptly generate a response tailored to your query, providing accurate and insightful information on neurology-related topics.\n",
    "\n",
    "<img src=\"./chatbox.png\" alt=\"NeuroBot Result Sample\" width=\"800\" height=\"800\" />\n",
    "\n",
    "\n",
    "## Technical Background: How AIMPED's NeuroBot Works\n",
    "AIMPED's NeuroBot operates on an advanced RAG (Recursive Abstractive Generation) system, transforming the way users interact with neurology-related queries. Here's a simplified breakdown of NeuroBot's workflow:\n",
    "\n",
    "- <b>Query Processing with Function Calling API:</b> When you ask a question, NeuroBot starts working using Anthropic's Function Calling API. First, it checks if your question is about neurology or similar topics. If it is, the API helps NeuroBot figure out more details or answers your question better. But if your question doesn't match, NeuroBot asks you to ask something more related to the topic.\n",
    "- <b>Document Retrieval:</b> When user asks NeuroBot about neurology, it looks for helpful documents from a collection of open-source materials about neurology. \n",
    "    - <b>Resource Preparation:</b> We basically have various text collection of documents related to neurology like proprietary and open-source clinical records, PubMed papers, and clinical neurology guidance books etc.\n",
    "    - <b> Tree Construction:</b>This collection is organized like a tree. Each part of the tree, called a node, holds important details from the documents. \n",
    "    \n",
    "    To find the right documents, NeuroBot starts by checking the list of these node details. By comparing these details, NeuroBot picks out documents that match your question best. It only brings back the most important and brief information, controlled by settings like `top_k` and `max_token`, so you get what you need quickly. All the picked documents are joined together to give you the full picture, but only up to a certain limit to keep things running smoothly.\n",
    "- <b>Response Generation:</b> After finding the right documents, NeuroBot uses Claude LLM to make a helpful response. This response is designed to be easy to understand and helpful, giving accurate answers to your questions about neurology.\n",
    "\n",
    "### Exploring NeuroBot's Tree Construction Process\n",
    "NeuroBot's tree construction process is a crucial component of its workflow, enabling efficient retrieval of relevant documents. Here's an overview of how the tree construction process works:\n",
    "- <b>Text Segmentation:</b>\n",
    "The process begins by segmenting the retrieval corpus into short, contiguous texts of a fixed length. These texts serve as the basis for further processing and analysis.\n",
    "- <b>Embedding and Clustering:</b>\n",
    "The segmented texts are embedded using an embedding model, capturing their semantic and contextual information. Next, a clustering algorithm based on Gaussian Mixture Models (GMMs) is employed to group similar text chunks together.\n",
    "- <b>Summarization:</b>\n",
    "A Language Model is utilized to summarize the grouped texts within each cluster. This summarization process condenses the information while preserving its relevance and coherence.\n",
    "- <b>Iterative Process:</b>\n",
    "The cycle of embedding, clustering, and summarization continues iteratively until further clustering becomes infeasible. This iterative approach results in a structured, multi-layered tree representation of the original documents.\n",
    "- <b>Efficiency and Scalability:</b>\n",
    "An important aspect of NeuroBot's tree construction process is its computational efficiency. The system scales linearly in terms of both build time and token expenditure, making it suitable for processing large and complex corpora.\n",
    "    \n",
    "\n",
    "<img src=\"./tree_structure.png\" alt=\"Tree Construction Process\" width=\"800\" height=\"800\" />\n",
    "    \n",
    "\n",
    "By constructing a comprehensive tree structure, AIMPED's NeuroBot ensures holistic understanding and efficient retrieval of relevant information, ultimately enhancing the quality of responses provided to users.\n",
    "\n",
    "\n",
    "## Feedback:\n",
    "The initial impression of NeuroBot is nothing short of astounding. Its ability to provide accurate and comprehensive responses to neurology-related queries are impressive and satisfying, establishing it as a reliable and indispensable medical companion.\n",
    "Benchmarking and testing are currently underway to further assess AIMPED's NeuroBot's performance and effectiveness. Preliminary results from these efforts are promising, confirming AIMPED's NeuroBot's superiority and underscoring its potential to revolutionize the accessibility and interaction of neurology-related information.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de68fd70",
   "metadata": {},
   "source": [
    "## Implementation Details: Exploring the Chatbot Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99721d02",
   "metadata": {},
   "source": [
    "### Construction of Hierarchical Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573a0af6",
   "metadata": {},
   "source": [
    "#### Get and install necessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ceaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install faiss-cpu numpy==1.26.3 scikit-learn sentence-transformers==2.2.2 tenacity==8.2.3 tiktoken==0.5.1 torch transformers==4.38.1 umap-learn==0.5.5 urllib3==1.26.6 anthropic\n",
    "!git clone https://github.com/parthsarthi03/raptor.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460c225c",
   "metadata": {},
   "source": [
    "#### Pre-requisits\n",
    "Before diving into the construction of the hierarchical tree, certain prerequisites need to be fulfilled:\n",
    "\n",
    "- <b>Model Class Preparation:</b> Prepare model classes for summarization, question-answering (QA), and embedding generation by extending the `BaseSummarizationModel`, `BaseQAModel`, and `BaseEmbeddingModel` classes, respectively.\n",
    "- <b>Resource Text Documents:</b> Gather the necessary text documents for building the hierarchical tree. In our case, a combination of proprietary and open-source clinical records, PubMed papers, and clinical neurology guidance books were utilized.\n",
    "\n",
    "#### Models Selection\n",
    "The selection of models for summarization, QA, and embedding is a crucial step in the construction process. For our purposes, we opted for the following:\n",
    "\n",
    "- <b>Summarization and QA:</b> Anthropic Claude LLM was chosen. Specifically, we selected claude-3-sonnet-20240229 for summarization and claude-3-haiku-20240307 for QA.\n",
    "- <b>Embedding Model:</b> \n",
    "Choosing the right embedding model for medical and healthcare tasks is crucial. To make the best choice, we compared different models using the BIOSSES benchmark dataset.\n",
    "\n",
    "\n",
    "#### Benchmarking and Evaluation\n",
    "To check how accurate our embedding model is, we need a dataset to compare it with. Since we're focusing on healthcare, it's best to use a dataset related to medical stuff. That's where BIOSSES comes in.\n",
    "\n",
    "BIOSSES is a dataset made for figuring out how similar sentences are in the medical field. It has 100 pairs of sentences, all taken from articles about medicine. You can learn more about BIOSSES here.\n",
    "\n",
    "Each pair of sentences in BIOSSES comes with a score. To test our models, we calculated the cosine similarity for each pair and then compared our model's score with the one in BIOSSES using Pearson correlation.\n",
    "\n",
    "We also measured how long each model took to create embeddings for a text of about 500 words.\n",
    "\n",
    "So based on the results, we have decided to use the `menadsa/BioS-MiniLM` embedding model. Below is the comparison result image.:\n",
    "<img src=\"./embedding_comparison.png\" alt=\"Embedding Model Comparison Result\" width=\"500\" height=\"500\" />\n",
    "\n",
    "#### Utilities\n",
    "The code snippet below defines three essential classes for different tree-building tasks, organized within a utilities module named `utils.py`:\n",
    "\n",
    "- <b>BioSEmbeddingModel:</b> Utilizes the SentenceTransformer library to create embeddings for biomedical text data.\n",
    "- <b>ClaudeHaikuQAModel:</b> Implements a question-answering model using the Anthropics API, interacting with the designated model \"`claude-3-haiku-20240307`\" to generate answers based on a given context.\n",
    "- <b>ClaudeSonnetSummarizationModel:</b> Represents a summarization model powered by the Anthropics API, utilizing the designated model \"`claude-3-sonnet-20240229`\" to generate summaries of text data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061db277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raptor import BaseSummarizationModel, BaseQAModel, BaseEmbeddingModel, RetrievalAugmentationConfig\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import anthropic\n",
    "import torch\n",
    "import os\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "\n",
    "\n",
    "class BioSEmbeddingModel(BaseEmbeddingModel):\n",
    "    def __init__(self, model_name=\"menadsa/BioS-MiniLM\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.model.to(\"cuda\")\n",
    "\n",
    "    def create_embedding(self, text):\n",
    "        encoded_text = self.model.encode(text)\n",
    "        text_tensor = torch.tensor(encoded_text).to(\"cuda\")\n",
    "        text_tensor_cpu = text_tensor.cpu()\n",
    "        return text_tensor_cpu.numpy()\n",
    "\n",
    "\n",
    "class ClaudeHaikuQAModel(BaseQAModel):\n",
    "\n",
    "    def __init__(self, model=\"claude-3-haiku-20240307\"):\n",
    "        self.model = model\n",
    "        self.client = anthropic.Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n",
    "\n",
    "    @retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "    def _attempt_answer_question(self, context, question, max_tokens=256, stream=False):\n",
    "        response = self.client.messages.create(\n",
    "            max_tokens=max_tokens,\n",
    "            model=self.model,\n",
    "            system=\"\"\"You are Question Answering Portal. Your job is to answer the question from the given context. Answer the question under 256 tokens without losing any information. Your answer must contain all the information required in the question. Don't mention \"Based on the details provided in the context\", just return the ANSWER only.\"\"\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Given Context:\\n{context} \\n Give the best full answer amongst the option to question:\\n {question}\",\n",
    "                },\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "        )\n",
    "        return response\n",
    "\n",
    "    def answer_question(self, context, question, max_tokens=256):\n",
    "        try:\n",
    "            return self._attempt_answer_question(context, question, max_tokens=max_tokens)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return e\n",
    "\n",
    "        \n",
    "class ClaudeSonnetSummarizationModel(BaseSummarizationModel):\n",
    "    def __init__(self, model=\"claude-3-sonnet-20240229\"):\n",
    "        self.model = model\n",
    "        self.client = anthropic.Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n",
    "\n",
    "    @retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "    def summarize(self, context, max_tokens=300, stop_sequence=None):\n",
    "        try:\n",
    "            response = self.client.messages.create(\n",
    "            max_tokens=max_tokens,\n",
    "            model=self.model,\n",
    "            system=\"You are a helpful assistant. Your job is to summarize the given context of around 300 tokens. Don't miss any information, create summary containing all the details.\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Write a summary of the following context, including as many key details as possible:\\nContext{context}:\",\n",
    "                },\n",
    "            ],\n",
    "            temperature=0.1,\n",
    "        )\n",
    "            return response.content[0].text.strip()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83360030",
   "metadata": {},
   "source": [
    "#### Tree Building\n",
    "\n",
    "Now, a crucial step in building a tree structure, importing necessary modules and classes, and then configures and initializes an instance of the `RetrievalAugmentation` class.\n",
    "\n",
    "- <b>Reading Source Documents:</b> The content of neurology source documents is read into memory.\n",
    "- <b>Configuration Setup:</b> Configure the `RetrievalAugmentationConfig` (`RAC`) object, specifying the summarization, embedding, and QA models, along with other parameters.\n",
    "- <b>Initialization:</b> Initialize an instance of the `RetrievalAugmentation` (`RA`) class using the configured `RAC`.\n",
    "- <b>Adding Documents:</b> Add the source documents to the retrieval augmentation pipeline.\n",
    "- <b>Saving Configuration:</b> Save the constructed retrieval augmentation tree to a specified location for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8941bea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from raptor import RetrievalAugmentation, RetrievalAugmentationConfig\n",
    "from utils import ClaudeSonnetSummarizationModel, SBertEmbeddingModel, ClaudeHaikuQAModel, BioSEmbeddingModel\n",
    "\n",
    "DOC_PATH = \"path_of_your_documents.txt\"\n",
    "SAVE_PATH = \"output/neuro_tree\"\n",
    "\n",
    "with open(DOC_PATH, 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "RAC = RetrievalAugmentationConfig(summarization_model=ClaudeSonnetSummarizationModel(), \n",
    "                                  embedding_model=BioSEmbeddingModel(),\n",
    "                                  qa_model=ClaudeHaikuQAModel(), tb_summarization_length=300)\n",
    "RA = RetrievalAugmentation(config=RAC)\n",
    "\n",
    "RA.add_documents(text)\n",
    "\n",
    "RA.save(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f7e5aa",
   "metadata": {},
   "source": [
    "With these steps completed, the hierarchical tree is constructed and ready for further implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ade24",
   "metadata": {},
   "source": [
    "#### NeuroAssistant\n",
    "The code snippet facilitates interaction with the Claude AI system to provide neurology-related information in response to user queries.\n",
    "\n",
    "`tools` list: Contains a dictionary specifying the available tools for neurology inquiries. In this case, there's one tool named `get_neuro_info` which retrieves answers for detailed neurology questions.\n",
    "\n",
    "`NeuroAssistant` class: In its constructor method, it initializes the Claude API client using the provided API key, specifies the model name, and assigns the list of available tools.\n",
    "\n",
    "The class includes several methods:\n",
    "- `get_neuro_info`: Retrieves neurology-related information based on a detailed question provided by the user.\n",
    "- `process_tool_call`: Processes the tool call and invokes the corresponding method based on the tool name.\n",
    "- `chat_with_claude`: Facilitates communication with the Claude system. It sends the user's message to Claude and receives a response. If the response indicates the use of a tool, it further processes the tool's output and sends the final response back to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e999e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "import re\n",
    "from utils import ClaudeHaikuQAModel\n",
    "import traceback\n",
    "import anthropic\n",
    "\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"name\": \"get_neuro_info\",\n",
    "        \"description\": \"Get the answer of the complete neuro related questions\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"detailed_question\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Detailed question with Event, Entity, Group, Medical Conditions etc.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"detailed_question\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "class NeuroAssistant:\n",
    "    def __init__(self):\n",
    "        self.client = anthropic.Anthropic(api_key=CLAUDE_API_KEY)\n",
    "        self.model_name = \"claude-3-haiku-20240307\"\n",
    "        self.tools = tools\n",
    "\n",
    "    def get_neuro_info(self, detailed_question, RA):\n",
    "        try:\n",
    "            result = RA.answer_question_faiss(question=detailed_question)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"Traceback: {traceback.format_exc()}\")\n",
    "            return f\"Error in getting neuro answer: {str(e)}\"\n",
    "\n",
    "    def process_tool_call(self, tool_name, tool_input, RA):\n",
    "        if tool_name == \"get_neuro_info\":\n",
    "            return self.get_neuro_info(tool_input[\"detailed_question\"], RA)\n",
    "\n",
    "    def chat_with_claude(self, input_message, RA):\n",
    "        print(f\"\\n{'='*50}\\nUser Message: {input_message}\\n{'='*50}\")\n",
    "\n",
    "        message = self.client.beta.tools.messages.create(\n",
    "            model=self.model_name,\n",
    "            system=\"You are the Neuro Bot, a knowledgeable source for neurology-related information. You ALWAYS use the TOOL if the question is related to medical condition, disease, patient, medical events etc. If the question seems missing the context, then complete it with the help of previous messages. Your role is to provide accurate and detailed answers to the user's queries in a clear and structured manner. If the input message is not related to neurology, you MUST clearly state 'I am the Neuro Bot, so I cannot help with any other queries. Please ask your queries related to neurology'. It is crucial to rely on verified information and never fabricate responses. Maintain a professional tone and prioritize the user's need for reliable information.\",\n",
    "            max_tokens=512,\n",
    "            messages=input_message,\n",
    "            tools=self.tools,\n",
    "        )\n",
    "\n",
    "        print(f\"\\nInitial Response:\")\n",
    "        print(f\"Message: {message} \")\n",
    "        print(f\"Stop Reason: {message.stop_reason}\")\n",
    "        print(f\"Content: {message.content}\")\n",
    "\n",
    "        input_tokens = message.usage.input_tokens\n",
    "        output_tokens = message.usage.output_tokens\n",
    "\n",
    "        tokens = {\"input_tokens\": input_tokens, \"output_tokens\": output_tokens}\n",
    "\n",
    "        print(f\"Tokenssssss>>>>>>: {tokens}\")\n",
    "\n",
    "        if message.stop_reason == \"tool_use\":\n",
    "            tool_use = next(block for block in message.content if block.type == \"tool_use\")\n",
    "            tool_name = tool_use.name\n",
    "            tool_input = tool_use.input\n",
    "\n",
    "            tool_api_result = self.process_tool_call(tool_name, tool_input, RA)\n",
    "\n",
    "            tool_result_input_tokens = tool_api_result.usage.input_tokens\n",
    "            tool_result_output_tokens = tool_api_result.usage.output_tokens\n",
    "\n",
    "            tokens['input_tokens'] += tool_result_input_tokens\n",
    "            tokens['output_tokens'] += tool_result_output_tokens\n",
    "\n",
    "            tool_result = tool_api_result.content[0].text.strip()\n",
    "\n",
    "            response = tool_result\n",
    "            return response, tokens\n",
    "\n",
    "        else:\n",
    "            response = message.content[0].text\n",
    "            print(f\"Returning direct response from CLAUDE:\\n{response}\")\n",
    "            return response, tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a89ce",
   "metadata": {},
   "source": [
    "The `get_neuro_info` function in the `NeuroAssistant` class above helps gather neurology information by using the features of the `RetrievalAugmentation` class. It mainly uses the `answer_question_fais`s function, which is a customized part of the `RetrievalAugmentation` class, to manage user questions efficiently.\n",
    "\n",
    "The `answer_question_faiss` method within the RetrievalAugmentation class performs two essential tasks:\n",
    "\n",
    "- Information Retrieval: This method invokes the `retrieve_information_from_faiss` method to retrieve relevant context chunks based on the user's query.`\n",
    "- Answer Generation: Once the relevant context is obtained, the method utilizes a question-answering model (`qa_model`) to generate an answer to the user's query.\n",
    "\n",
    "Below is the relevant code snippet demonstrating the `answer_question_faiss` method within the `RetrievalAugmentation` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd3f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalAugmentation:\n",
    "    # Additional methods already present in this class:\n",
    "    \n",
    "    \n",
    "    def answer_question_faiss(\n",
    "        self,\n",
    "        question,\n",
    "        top_k: int = 10,\n",
    "        max_tokens: int = 3500,\n",
    "    ):\n",
    "         \"\"\"\n",
    "        Answers the given question using information retrieved from FAISS index.\n",
    "\n",
    "        Args:\n",
    "            question (str): The question to be answered.\n",
    "            top_k (int): The number of top results to consider.\n",
    "            max_tokens (int): The maximum number of tokens to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            str: The answer to the question.\n",
    "        \"\"\"\n",
    "        context = self.retriever.retrieve_information_from_faiss(question, top_k, max_tokens)\n",
    "        logging.info(\"Context prepared: ✔\")\n",
    "        answer = self.qa_model.answer_question(context, question)\n",
    "\n",
    "        return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28561529",
   "metadata": {},
   "source": [
    "The `retrieve_information_from_faiss` function in the `TreeRetriever` class helps fetch relevant context pieces from a precalculated embedding index using the FAISS library. It was added as a custom feature to expand the capabilities of the `TreeRetriever` class.\n",
    "\n",
    "Here's how the function works:\n",
    "\n",
    "- Node List Retrieval: It gathers a list of nodes from a designated tree structure.\n",
    "- Embedding Preparation: It calculates and stores the embeddings for each node in the node list.\n",
    "- Index Setup: Using the FAISS library, it sets up an index based on the computed embeddings.\n",
    "- Query Processing: The function handles the user's query, retrieves the most suitable context pieces based on the query using the FAISS index, and combines them to create the final context string.\n",
    "Here's a code snippet demonstrating the implementation of the `retrieve_information_from_fais`s function within the `TreeRetriever` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27637f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeRetriever(BaseRetriever):\n",
    "    # Additional methods already present in this class:\n",
    "\n",
    "    \n",
    "    \n",
    "    # Custom method for retrieving information from FAISS index\n",
    "    def retrieve_information_from_faiss(self, query: str, top_k: int, max_tokens: int) -> str:\n",
    "        \"\"\"\n",
    "        Retrieves relevant information from the FAISS index based on the provided query.\n",
    "\n",
    "        Args:\n",
    "            query (str): The query string.\n",
    "            top_k (int): The number of top results to retrieve.\n",
    "            max_tokens (int): The maximum number of tokens to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            str: The retrieved information.\n",
    "        \"\"\"\n",
    "        node_list = get_node_list(self.tree.all_nodes)\n",
    "\n",
    "        self.context_chunks = [node.text for node in node_list]\n",
    "\n",
    "        self.embeddings = np.array(\n",
    "            [node.embeddings[self.context_embedding_model] for node in node_list],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "        self.index = faiss.IndexFlatIP(self.embeddings.shape[1])\n",
    "        self.index.add(self.embeddings)\n",
    "\n",
    "        query_embedding = np.array(\n",
    "            [\n",
    "                np.array(\n",
    "                    self.create_embedding(query),\n",
    "                    dtype=np.float32,\n",
    "                ).squeeze()\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        context = \"\"\n",
    "        self.use_top_k = True\n",
    "        if self.use_top_k:\n",
    "            _, indices = self.index.search(query_embedding, top_k)\n",
    "            total_tokens = 0\n",
    "            for i in range(self.top_k):\n",
    "                # context += self.context_chunks[indices[0][i]]\n",
    "                text = self.context_chunks[indices[0][i]]\n",
    "                text_processor = TextProcessor()\n",
    "                anthropic_client = text_processor.get_anthropic_client()\n",
    "                tokens = anthropic_client.count_tokens(text)\n",
    "                if total_tokens + tokens > max_tokens:\n",
    "                    break\n",
    "                total_tokens += tokens\n",
    "                context += text\n",
    "\n",
    "        else:\n",
    "            range_ = int(self.max_context_tokens / self.max_tokens)\n",
    "            _, indices = self.index.search(query_embedding, range_)\n",
    "            total_tokens = 0\n",
    "            for i in range(range_):\n",
    "                tokens = len(self.tokenizer.encode(self.context_chunks[indices[0][i]]))\n",
    "                context += self.context_chunks[indices[0][i]]\n",
    "                if total_tokens + tokens > self.max_context_tokens:\n",
    "                    break\n",
    "                total_tokens += tokens\n",
    "\n",
    "        return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1539a40",
   "metadata": {},
   "source": [
    "#### NeuroBot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6afca20",
   "metadata": {},
   "source": [
    "##### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba70fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from typing import Dict, Union\n",
    "import requests\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from decouple import config\n",
    "from tools import api_sample, prompt, ready_messages\n",
    "from raptor import RetrievalAugmentation, RetrievalAugmentationConfig\n",
    "from utils import ClaudeSonnetSummarizationModel, BioSEmbeddingModel, ClaudeHaikuQAModel, SBertEmbeddingModel\n",
    "from neuro_assistant import NeuroAssistant\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8846163",
   "metadata": {},
   "source": [
    "##### Logging Configuration Setup\n",
    "Initializing logging for the Python script/module, allowing for logging messages with various severity levels such as INFO, WARNING, ERROR, etc., along with timestamps and other relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921c6e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# Configure the logger\n",
    "logging.basicConfig(level=logging.INFO,format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "# Create a logger object\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e7b23a",
   "metadata": {},
   "source": [
    "The `NeuroBot` class is the central part of a chatbot system designed to manage neurology-related questions. It handles user input, communicates with external APIs, and generates suitable replies. Here's a summary of its main features and attributes:\n",
    "\n",
    "- `Initialization`: When created, the class sets up various attributes like API keys, message storage, and configurations for external APIs. It also prepares models and tools needed for processing queries.\n",
    "- `extract_role_and_content` method: This function refine the incoming messages, keeping only the relevant role and content while discarding unnecessary data.\n",
    "- `ready_response` method: If there are any errors during processing, this function sends a predefined response.\n",
    "- `predict` method: The core function predicts responses based on user queries. It processes incoming data, generates content using the neurology assistant, and handles any encountered errors. This ensures the chatbot gives meaningful responses reliably.\n",
    "\n",
    "Overall, the NeuroBot class manages the flow of information in the chatbot system, facilitating smooth interaction between users and the neurology assistance framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f39f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\")\n",
    "ANTHROPIC_API_KEY = \"sk-xxxxxx\"\n",
    "os.environ['ANTHROPIC_API_KEY'] = ANTHROPIC_API_KEY\n",
    "\n",
    "\n",
    "class NeuroBot:\n",
    "    def __init__(self):\n",
    "        self.ANTHROPIC_API_KEY = config(\"ANTHROPIC_API_KEY\")\n",
    "        self.messages = []\n",
    "        self.text = \"\"\n",
    "        self.api_result = None\n",
    "        self.voice = None\n",
    "        self.extra_fields = None\n",
    "        self.stream = False\n",
    "        self.counter = 0\n",
    "        self.data_type = [\"data_json\", \"data_url_speak\"]\n",
    "        self.error_counter = 0\n",
    "        self.tree_path = \"output/neuro_tree\"\n",
    "        self.neuro_assistant = NeuroAssistant()\n",
    "        self.RAC = RetrievalAugmentationConfig(summarization_model=ClaudeSonnetSummarizationModel(), \n",
    "                                          embedding_model=BioSEmbeddingModel(),\n",
    "                                          qa_model=ClaudeHaikuQAModel(), tb_summarization_length=300)\n",
    "        self.RA = RetrievalAugmentation(config=self.RAC, tree=self.tree_path)\n",
    "        \n",
    "        \n",
    "        \n",
    "    async def extract_role_and_content(self, messages):\n",
    "        # For getting rid of \"processed\" key\n",
    "        original_messages = []\n",
    "        for message in messages:\n",
    "            if \"role\" in message and \"content\" in message:\n",
    "                extracted_message = {\n",
    "                    \"role\": message[\"role\"],\n",
    "                    \"content\": message[\"content\"]\n",
    "                }\n",
    "                original_messages.append(extracted_message)\n",
    "        return original_messages\n",
    "\n",
    "        \n",
    "    async def ready_response(self):\n",
    "        ready_messages = [\"Apologies, but I did not comprehend your statement. Would you kindly rephrase it for me?\", \n",
    "                  \n",
    "                  \"Apologies for the inconvenience. An error has occurred. Kindly restate your request.\",\n",
    "                  \"I apologize for the inconvenience caused by a technical difficulty, which resulted in my failure to comprehend your statement. Kindly request you to reiterate it, if you wouldn't mind.\", \n",
    "                 ]\n",
    "        self.error_counter += 1\n",
    "        self.text = ready_messages[self.error_counter - 1]\n",
    "        return json.dumps({\"status\": True, \n",
    "                                  \"output\": {\n",
    "                                      \"data_json\": {\n",
    "                                          \"text\": self.text,\n",
    "                                          \"extra_fields\": self.extra_fields,\n",
    "                                      }\n",
    "                                  }\n",
    "                                  })\n",
    "\n",
    "\n",
    "    async def predict(self, payload: Dict, headers: Dict[str, str] = None) -> Dict:\n",
    "        try:\n",
    "            if payload:\n",
    "                logger.info(f\"Payload received: ✔\")\n",
    "                self.extra_fields = payload['messages']\n",
    "            else:\n",
    "                logger.info(f\"No prompt messages received\")\n",
    "                return json.dumps({\"status\": False, \"error\": \"No prompt messages received\"})\n",
    "\n",
    "            # CONTENT GENERATION\n",
    "            try:\n",
    "                self.messages = await self.extract_role_and_content(self.extra_fields)\n",
    "                logger.info(f\"Generating content...\")\n",
    "                timer = time.time()\n",
    "\n",
    "                self.result, tokens_obj = self.neuro_assistant.chat_with_claude(input_message=prompt + self.messages, RA=self.RA)\n",
    "\n",
    "                logger.info(f\"Content generated successfully in {time.time() - timer} seconds\")\n",
    "                text = self.result\n",
    "\n",
    "                # OUTPUT\n",
    "                self.extra_fields.append({\"role\": \"assistant\", \"content\": text})\n",
    "                return json.dumps({\"used_credits\" : self.used_credits,\n",
    "                    \"status\":True,\n",
    "                    \"data_type\":self.data_type,\n",
    "                    \"output\":{\"data_json\":{\"text\":text},\n",
    "                              \"extra_fields\":self.extra_fields,\n",
    "                                }})\n",
    "\n",
    "            except Exception as e:\n",
    "                if self.error_counter < 3:\n",
    "                    return json.loads(await self.ready_response())\n",
    "                else:\n",
    "                    logger.error(f\"Error while generating content: {str(e)}\")\n",
    "                    return json.dumps({\"status\": False, \"error\": f\"Sorry while generating content an error occurred. Please try again later. Error message: {str(e)}\"})\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error while predicting: {str(e)}\")\n",
    "            return json.dumps({\"status\": False, \"error\": f\"Sorry while predicting an error occurred. Please try again later. Error message: {str(e)}\"})\n",
    "\n",
    "        finally:\n",
    "            logger.info(f\"Predicting finished:✔\")\n",
    "            self.api_result = self.extra_fieldsl = None\n",
    "            self.text = \"\"\n",
    "            self.messages = []\n",
    "            logger.info(f\"All variables are reset:✔\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d143d82",
   "metadata": {},
   "source": [
    "## Running the NeuroBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee09647",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    model = NeuroBot()\n",
    "    payload = {\n",
    "        \"messages\": \n",
    "        [\n",
    "            {'role': 'user', 'content': '\"I have questions about neurology and neurological conditions. I need clear, detailed answers. Can you provide information about neurological disorders, symptoms, diagnostic procedures, treatment options, and anything else related to neurology? Please ensure the information is accurate and easy to understand.\"\\n        '}, \n",
    "            {'role': 'assistant', 'content': \"Hello! I am the Neuro Bot, here to provide detailed and accurate information about neurology. Whether you have questions about neurological disorders, symptoms, diagnostic procedures, treatment options, or any other neurology-related inquiries, I'm here to help. I ALWAYS uses the TOOLS to answer the queries. I'll present the information in a clear, structured format for easy understanding. If there's something I don't know, I'll be sure to tell you. How can I assist you today?\\n        \"}, \n",
    "            {\"role\": \"user\", \"content\": \"What is EPILEPSY\"}\n",
    "        ],\n",
    "    }\n",
    "    \n",
    "    res = await model.predict(payload)\n",
    "    res = res['output']['data_json']['text']\n",
    "    print(\"RES>>>\" ,res)\n",
    "    \n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e2ddfa",
   "metadata": {},
   "source": [
    "## Running NeuroBot on Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbd09fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio==3.48.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb9fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import asyncio\n",
    "\n",
    "# Your main function\n",
    "async def main(inp_text, history):\n",
    "    model = NeuroBot()\n",
    "    payload = {\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": inp_text}],\n",
    "    }\n",
    "    res = await model.predict(payload)\n",
    "    res = res['output']['data_json']['text']\n",
    "    return res\n",
    "\n",
    "# Creating the Gradio interface\n",
    "iface = gr.ChatInterface(fn=main, title=\"NeuroBot Chat\")\n",
    "\n",
    "# Running the interface\n",
    "iface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e4df60",
   "metadata": {},
   "source": [
    "## Future Directions: Specialized Subdomains\n",
    "\n",
    "Even though there are lots of medical language models out there, the medical field is huge, so it's important to be really precise when using fancy technologies like RAG or training LLMs. This helps make sure they're super accurate and reliable. NeuroBot shows us that by focusing on specific areas like neurology, it can be even more accurate than those general medical models. And we are planning to dive into other areas like psychiatry, infection, and oncology. That means there's a bright future ahead for medical chatbots that really know their stuff in different medical fields."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
